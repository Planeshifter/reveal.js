<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Sentiment Mining of the Blogosphere</title>

		<meta name="description" content="A framework for easily creating beautiful presentations using HTML">
		<meta name="author" content="Philipp Burckhardt">

		<meta name="apple-mobile-web-app-capable" content="yes" />
		<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

		<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

		<link rel="stylesheet" href="css/reveal.css">
		<link rel="stylesheet" href="css/theme/default.css" id="theme">

		<!-- For syntax highlighting -->
		<link rel="stylesheet" href="lib/css/zenburn.css">

		<!-- If the query includes 'print-pdf', use the PDF print sheet -->
		<script>
			document.write( '<link rel="stylesheet" href="css/print/' + ( window.location.search.match( /print-pdf/gi ) ? 'pdf' : 'paper' ) + '.css" type="text/css" media="print">' );
		</script>

		<!--[if lt IE 9]>
		<script src="lib/js/html5shiv.js"></script>
		<![endif]-->
		
		<!-- {{{ MathJax Config -->
	<script type="text/x-mathjax-config">
		MathJax.Hub.Config({
			"HTML-CSS": {
				scale: 95,
				showMathMenu: false,
				mtextFontInherit: true,
				preferredFont: "TeX",
				styles: {
					".MathJax_Display": {
						margin: "0.75em 0em"
					}
				}
			},
			"SVG": {mtextFontInherit: true, scale: 95, showMathMenu: false},
  			jax: ["input/TeX","output/HTML-CSS"],
			tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
  			extensions: ["tex2jax.js"],
  			TeX: {
    			//extensions: ["AMSmath.js","AMSsymbols.js","noErrors.js","noUndefined.js"]
    			extensions: ["AMSmath.js","AMSsymbols.js"]
			}
		});
	</script>
	<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/2.1-latest/MathJax.js"></script>
	<!-- }}} -->
		
	</head>

	<body>

		<div class="reveal">

			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">
				<section>
					<h1>Sentiment Mining of the Blogosphere</h1>
					<p>
						<small>A Presentation by <a href="http://philipp-burckhardt.com">Philipp Burckhardt</a> for the PhD Seminar at <br> 
						11/25/2013, Heinz College, Carnegie Mellon University</small>
					</p>
				</section>
							
				<section style="display: block;">
					<h2>Long-Term Objectives</h2>
					<ul>
						<li>Sentiment mining of the Blogosphere (public opinion research, marketing applicationss)</li>
						<li>Understand how messages about entities are spreading on the Blogosphere (via dynamic network models)</li>
						<li>Identify opinion leaders and latent communities</li>			
					</ul>			
				</section>
				
				<section >
			    <h2 style="vertical-align: center">Challenge: How do we cope with the massive overkill of information in the Internet age?</h2>
			    	
				</section>			
				
				<section>
					<section>
					<h2> Excursion: NewscrapeR </h2>
					<p>  I have developed tool for scraping Internet data. Used in analysis of newspaper articles and their repurcussions on Twitter. </p>
					<aside class="notes">Principles of Topic Modelling. Need to go deeper: Sentiment analysis, semantics and relationship analysis. </aside>
					</section>
					<section>
 					<h2> NewscrapeR (2)</h2>	
 					<ul>
 						<li>Usage of YQL (Yahoo! Query Language), which streamlines the process of scraping data from the Web by circumventing the APIs of
 							the individual providers</li>
 						<li>Automated Scheduling of Scraping Tasks</li>

 					</ul> 
 					</section>
 					
 				    <section>
 					<h2> NewscrapeR (3)</h2>	
						<div style="position:absolute; width: 200%; top: 0px; left: -450px">
							<iframe src="http://philipp-burckhardt.com/Red-Raging-Golem/" width="1200" height="700"></iframe>
 						</div>
 					</ul> 
 					</section>
 					
				</section> 
				
				<section>
				 <h2> Technorati.com </h2>
				 <ul> 
				 <li> Website which has indexed and categorized more than 112 million blogs (in English language)</li>
				 <li> Technorati provides for each blog's an "authority" score based on the number of unique blogs linking to the blog over the previous six months.</li>		 	
				 </ul>
				
					
				</section>
				
				<section>
					<div style="position:absolute; width: 200%; top: 0px; left: -450px"><iframe src="http://technorati.com/blogs/directory/" width="1200" height="700"></iframe>
 					</div>
				</section>
					
				<section data-background="#4d7e65" data-transition="linear" data-background-transition="slide">
					<h1> Natural Language Processing</h1>
				</section>
				
				
				<section data-transition="linear" data-background="#8c4738" data-background-transition="slide">
				<h2>Named Entity Recognition</h2>
				<div align="left">
				<p> The traditional method of extracting information from the Web, keywordbased search, is insufficient: One can only find what one is looking for.</p>
				<p> Instead: Use the learned entities to annotate texts.</p>
				</div>

				</section>
				
				<section data-transition="linear" data-background-transition="slide">
 				<object style="position:absolute; width: 200%; top: -300px; left: -450px" type="image/svg+xml" data="lod-cloud.png"></object>
 				<div style="position: relative; color:black; background-color:white;background-clip:content-box; border:2px solid grey">
 					<h2 style="color:black">Exploiting Information about the World using Linked Data</h2>
 					<small>Linking Open Data cloud diagram, by Richard Cyganiak and Anja Jentzsch <a href='http://lod-cloud.net/'>http://www.lod.cloud.net</a></small>
 				</div>
 				</section>
 				
 				<section>
 					<div style="position:absolute; width: 200%; top: 0px; left: -450px"><iframe src="http://dbpedia.org/page/Barack_Obama" width="1200" height="700"></iframe>
 					</div>
 				</section>
 				
 				<section>
 					<section>
 				<div style="display:block" >Using Semantic Web Technologies, I have built an entity recognition system which can be automatically extended (includes already > 50,000 entities).
 				</div>
 			    <a href="http://philipp-burckhardt.com/Semantik/tokenizer" target="_blank">Let's see it in action</a>
 			    	</section>
 			
            <section style="font-size: 0.9em; display: block;" data-transition="fade" data-background-transition="fade">
                <h2> Semantic Web Technologies </h2>
                <div align="left">
                <b>RDF (Resource Description Framework) </b>
                <ul> 
                	<li>Allows to define triples of 'subject', 'predicate', 'value'</li>
                	<li>Designed to be read and understood by computers.</li>
                	<li> URIs are used as names for entities. 
                	  <li>HTTP URIs can be looked up to obtain useful information</li>
                	  <li>Allows to deal with name disambiguation problem</li>
                	</li>
                </ul> <br>
                <b>OWL (Web Ontology Language)</b>
                <ul>           
                	<li>Based on RDF, OWL allows logical statements and inference</li>
                </ul>      
                </div>
            </section>
 				</section>
				
				<section>
					<h2>Problem Statement:</h2>
				    <ol>
				    <li> Classify web blogs into categories using both text data and the information contained in the connections to other blogs (Toy Example)</li>
				    <li> Infer the sentiment (positive / negative) of posts about certain entities based on the relevant subset of documents and the implied network structure. </li>
				    </ol>
				</section>
				
			 <section class="present" style="display: block;" data-transition="fade" data-background-transition="fade">
					<h2>Blog Network Structure</h2>
					
					  <div class="definition">
					  <p>Construct (asymmetric) adjacency matrix $\mathbf{A}$  <br>
					  with elements </p>
					  \[{A_{ij}} = \text{#  of times blog i links to blog j} 
					   \]
					  </div>
				</section>			
								
	                         				
			    <section style="font-size: 0.9em; display: block;">
					<h2>Collective Classification</h2>
					<ul>
					<li>Ordinary classification methods such as Logistic Regression or Naive Bayes predict the value for actor $Y_i$  using a feature vector $x_i$  containing the observed attributes of the observation</li>
					<li>In collective classification, one uses also information about actors in the neighbourhood of $Y_i$ in the prediction task</li>
					<li>Goal is then to infer the class labels with either the maximum joint probability or the maximum marginal probability for each node. </li>
					</ul>
				</section>
				
				<section style="font-size: 0.75em; display: block;">
						<h2> Estimation Techniques: </h2>
						<ul>
						<li> <b> Iterative Classifier Approach: </b>
						<p>One at a time, generate the best classification for a single instance given all other parts of the problem (i.e. the
						correct labelling of the other instances)</p>
						</li>	
						<li><b>Gibbs Sampling:</b>	
						<p>Iteratively assign class labels to all nodes by drawing from the conditional distribution of the current node given the others. 
						After a sufficient number of iterations, count the number of times a given node was assigned a certain label and normalize to get probability
						estimates</p>
						</li>
						<li>
						<b>Variational Methods:</b>
							<ul>
							<li>Loopy Belief Propagation</li> 
							<li>Mean-Field Relaxation Labeling (MF)</li>
							<li>Methods have in common that a trial distribution is chosen which is in some sense comparable to the true distribution (e.g. in terms of Kullbackâ€“Leibler divergence) 
								but much simpler to work with</li>
							</ul>
						</li>
						</ul>
					</section>
										
				<section>
				  <section>
					<h2>Open Questions:</h2>
					<ul>
					<li>Feature Extraction: Going beyond uni-grams. But how to aggregate & score adjectives, how to use DBpedia results?</li>
					<li>Study the empricial performance of collective classification compared to classicial approaches. Under which conditions does
				    it perform better? </li>
					</ul>
				 </section>
				 <section>
				 <h2>SPARQL Call</h2>
				 	                    <pre><code data-trim contenteditable>
   SELECT DISTINCT ?person ?name ?occupation WHERE {
?person a dbpedia-owl:Person .
?person rdfs:label ?name.
?person dbpprop:occupation ?occupation .
FILTER (regex(?name, "^A")) .
FILTER (lang(?name) = "en") .
}
LIMIT 100
                                        </code></pre>
				 </section>
				 <section>
				 	
				 	<div style="position:absolute; width: 200%; top: 0px; left: -450px">
							<iframe src="http://dbpedia.org/sparql?default-graph-uri=http%3A%2F%2Fdbpedia.org&query=+++SELECT+DISTINCT+%3Fperson+%3Fname+%3Foccupation+WHERE+{%0D%0A%3Fperson+a+dbpedia-owl%3APerson+.%0D%0A%3Fperson+rdfs%3Alabel+%3Fname.%0D%0A%3Fperson+dbpprop%3Aoccupation+%3Foccupation+.%0D%0AFILTER+%28regex%28%3Fname%2C+%22^A%22%29%29+.%0D%0AFILTER+%28lang%28%3Fname%29+%3D+%22en%22%29+.%0D%0A}%0D%0ALIMIT+100&format=text%2Fhtml&timeout=&debug=on" width="1200" height="700" style="border: outset; background-color:white"></iframe>
 					</div>
				 	
				 </section>
				</section>
				
				
				<section>
				  <h2>Currently Discussed Research Projects</h2>
				  <ul>
				  	<li>Possible participation in a project led by <b>Rema Padman</b> and <b>Jamie Callan</b> which tries to use content from internet blogs
				  		and forums of patients with chronic kidney disease to inform doctor's decisisions and ways of approaching patients.  </li>
				  	<li> Extracting Rich Network Structure from Text	</li>	
				  	<li> Analysis of Network Evolution	</li>
				  </ul>
				</section>
	
				<section>
				<h1>Discussion</h1>	
				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.min.js"></script>

		<script>

			// Full list of configuration options available here:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				theme: Reveal.getQueryHash().theme, // available themes are in /css/theme
				transition: Reveal.getQueryHash().transition || 'default', // default/cube/page/concave/zoom/linear/fade/none

				// Optional libraries used to extend on reveal.js
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true, condition: function() { return !!document.body.classList; } },
					{ src: 'plugin/notes/notes.js', async: true, condition: function() { return !!document.body.classList; } }
				]
			});
			Reveal.addEventListener( 'slidechanged', function( event ) {
    		MathJax.Hub.Rerender();
			} );

		</script>

	</body>
</html>
